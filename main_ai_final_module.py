import os
import pandas as pd
import numpy as np
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import List, Optional
from sklearn.preprocessing import StandardScaler
from datetime import datetime, time
import redis
import uvicorn
from dotenv import load_dotenv
from sqlalchemy import create_engine, text

# LangChain ë° OpenAI ê´€ë ¨ ì„í¬íŠ¸
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser


# --- 1. Pydantic ëª¨ë¸ ì •ì˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---

# ë‹¤ì´ì–´íŠ¸ ì •ë³´ ëª¨ë¸
class DietInfo(BaseModel):
    height: Optional[int] = Field(default=None, description="í‚¤ (cm)")
    weight: Optional[int] = Field(default=None, description="ëª¸ë¬´ê²Œ (kg)")


# ê°€ê²© ë²”ìœ„ ëª¨ë¸
class PriceRangeInput(BaseModel):
    minPrice: Optional[int] = Field(default=None, description="ìµœì†Œ ê°€ê²©")
    maxPrice: Optional[int] = Field(default=None, description="ìµœëŒ€ ê°€ê²©")


# ì‚¬ìš©ì ì…ë ¥ ëª¨ë¸
class UserInput(BaseModel):
    category: str = Field(description="ì¹´í…Œê³ ë¦¬: 'diet', 'vegan', 'low_sugar', 'muslim' ì¤‘ í•˜ë‚˜")
    diet: Optional[DietInfo] = Field(default=None, description="ë‹¤ì´ì–´íŠ¸ ì •ë³´ (category='diet'ì¼ ë•Œë§Œ)")
    meals: List[str] = Field(description="ì¶”ì²œë°›ì„ ì‹ì‚¬: ['breakfast', 'lunch', 'dinner'] ì¤‘ ì„ íƒ")
    priceRange: PriceRangeInput = Field(description="ê°€ê²© ë²”ìœ„")
    prompt: str = Field(description="ì‚¬ìš©ì ìš”ì²­ì‚¬í•­ (ì˜ˆ: 'êµ­ìˆ˜ ë§ê³  ë°¥')")
    location: List[str] = Field(default=[], description="ìœ„ì¹˜: ['science_campus', 'humanities_campus'] ì¤‘ ì„ íƒ")


# UserPreferences: ë‚´ë¶€ ì²˜ë¦¬ìš©ìœ¼ë¡œ ë³€í™˜ëœ ëª¨ë¸
class UserPreferences(BaseModel):
    user_id: Optional[int] = None
    budget: Optional[int] = Field(default=10000, description="ìµœëŒ€ ì˜ˆì‚° (ì›)")
    min_budget: Optional[int] = Field(default=None, description="ìµœì†Œ ì˜ˆì‚° (ì›)")
    preferred_categories: List[str] = Field(default=[], description="ì„ í˜¸ ì¹´í…Œê³ ë¦¬ (ì‚¬ìš© ì•ˆ í•¨. 'location'ìœ¼ë¡œ ëŒ€ì²´ë¨)")
    meal_type: str = Field(default="ì ì‹¬", description="ì‹ì‚¬ ì‹œê°„ëŒ€: ì•„ì¹¨/ì ì‹¬/ì €ë… (ì‹œê°„ í•„í„°ë§ì— ì‚¬ìš©)")
    target_meals: List[str] = Field(default=["lunch"], description="['morning', 'lunch', 'dinner']")
    user_prompt: str = Field(default="", description="ì‚¬ìš©ì ì„¸ë¶€ ìš”ì²­")

    # ì˜ì–‘ ê´€ë ¨ ì„ í˜¸ë„
    prefer_high_protein: bool = Field(default=False, description="ê³ ë‹¨ë°± ì„ í˜¸ (ë¹„í™œì„±í™”)")
    prefer_low_calorie: bool = Field(default=False, description="ì €ì¹¼ë¡œë¦¬ ì„ í˜¸ (ìœ ì¼í•˜ê²Œ ì‚¬ìš©)")
    prefer_low_sodium: bool = Field(default=False, description="ì €ë‚˜íŠ¸ë¥¨ ì„ í˜¸ (ë¹„í™œì„±í™”)")

    # ì‚¬ìš©ìì˜ 'ëª©í‘œ' ì¹´í…Œê³ ë¦¬ (ì˜ˆ: 'vegan', 'muslim')
    category: Optional[str] = Field(default=None, description="ì¹´í…Œê³ ë¦¬")
    height: Optional[int] = Field(default=None, description="í‚¤")
    weight: Optional[int] = Field(default=None, description="ëª¸ë¬´ê²Œ")
    location: List[str] = Field(default=[], description="ìœ„ì¹˜ ì •ë³´ (ìº í¼ìŠ¤ í•„í„°ë§ì— ì‚¬ìš©)")


# AI Aì™€ Bê°€ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ë“¤ (ê¸°ì¡´ê³¼ ë™ì¼)
class MenuCandidate(BaseModel):
    restaurant_name: str
    menu_name: str
    price: int
    base_score: float
    tags: List[str]


class PriceRange(BaseModel):
    min: Optional[int] = None
    max: Optional[int] = None


class RecommendationRequest(BaseModel):
    candidates: List[MenuCandidate]
    user_prompt: str
    price: Optional[PriceRange] = Field(default=None, description="ì‚¬ìš©ì ê°€ê²© ì œí•œ")
    target_meals: List[str] = Field(description="ì¶”ì²œë°›ê³ ì í•˜ëŠ” ë¼ë‹ˆ ëª©ë¡")
    conversation_history: Optional[List[str]] = []


class RecommendedMenu(BaseModel):
    restaurant_name: str = Field(description="ì‹ë‹¹ ì´ë¦„")
    menu_name: str = Field(description="ë©”ë‰´ ì´ë¦„")
    price: int = Field(description="ë©”ë‰´ì˜ ì‹¤ì œ ê°€ê²©")
    justification: str = Field(description="ì´ ë©”ë‰´ë¥¼ ì¶”ì²œí•˜ëŠ” ì´ìœ  (LLMì´ ì‘ì„±)")
    new_score: float = Field(description="LLMì´ ì¬í‰ê°€í•œ ìµœì¢… ì ìˆ˜ (0.0 ~ 1.0)")
    reason_hashtags: List[str] = Field(description="ì¶”ì²œ ì´ìœ ë¥¼ ìš”ì•½í•˜ëŠ” 3-5ê°œì˜ í•´ì‹œíƒœê·¸")


class FinalRecommendation(BaseModel):
    morning: Optional[RecommendedMenu] = Field(default=None, description="ì¶”ì²œ ì•„ì¹¨ ë©”ë‰´")
    lunch: Optional[RecommendedMenu] = Field(default=None, description="ì¶”ì²œ ì ì‹¬ ë©”ë‰´")
    dinner: Optional[RecommendedMenu] = Field(default=None, description="ì¶”ì²œ ì €ë… ë©”ë‰´")


# --- 2. ì…ë ¥ ë³€í™˜ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---

def convert_user_input(user_input: UserInput) -> UserPreferences:
    """
    (ìˆ˜ì •ë¨) í”„ë¡ íŠ¸ì—”ë“œ JSON í˜•ì‹ì„ ë‚´ë¶€ ì²˜ë¦¬ìš© UserPreferencesë¡œ ë³€í™˜
    - 'location' í•„ë“œë¥¼ 'preferred_categories'ê°€ ì•„ë‹Œ 'location' í•„ë“œì— ê·¸ëŒ€ë¡œ ì „ë‹¬
    """
    # ì‹ì‚¬ íƒ€ì… ë³€í™˜
    meal_mapping = {
        "BREAKFAST": "morning",
        "LUNCH": "lunch",
        "DINNER": "dinner"
    }
    target_meals = [meal_mapping.get(m.upper(), m.lower()) for m in user_input.meals]

    meal_type_mapping = {
        "morning": "ì•„ì¹¨",
        "lunch": "ì ì‹¬",
        "dinner": "ì €ë…"
    }
    meal_type = meal_type_mapping.get(target_meals[0], "ì ì‹¬") if target_meals else "ì ì‹¬"

    # 'DIET'ì¼ ë•Œë§Œ ì €ì¹¼ë¡œë¦¬ í”Œë˜ê·¸ í™œì„±í™”
    prefer_low_calorie = False
    if user_input.category.upper() == "DIET":
        prefer_low_calorie = True

    prefer_high_protein = False
    prefer_low_sodium = False

    preferred_categories = []

    return UserPreferences(
        budget=user_input.priceRange.maxPrice,
        min_budget=user_input.priceRange.minPrice,
        preferred_categories=preferred_categories,  # <- ì´ì œ ì‚¬ìš© ì•ˆ í•¨
        meal_type=meal_type,
        target_meals=target_meals,
        user_prompt=user_input.prompt,
        prefer_high_protein=prefer_high_protein,
        prefer_low_calorie=prefer_low_calorie,
        prefer_low_sodium=prefer_low_sodium,
        category=user_input.category,  # <-- 'VEGAN', 'MUSLIM' ë“± ì „ë‹¬
        height=user_input.diet.height if user_input.diet else None,
        weight=user_input.diet.weight if user_input.diet else None,
        location=user_input.location  # <-- 'science_campus' ë“±ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
    )


# --- 3. ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤ (ê¸°ì¡´ê³¼ ë™ì¼) ---

class MenuDataPreprocessor:
    """
    (ìˆ˜ì •ë¨) 'ì—´ëŸ‰', 'ê°€ê²©', 'íƒœê·¸', 'ì¹´í…Œê³ ë¦¬', 'í‰ì ', 'ì˜ì—…ì‹œê°„', 'ìº í¼ìŠ¤' ê¸°ë°˜ ì „ì²˜ë¦¬
    """

    def __init__(self):
        self.scaler = StandardScaler()
        self.menu_features = None
        self.menu_df = None
        self.db_engine = self._create_db_engine()

    def _create_db_engine(self):
        """
        .env íŒŒì¼ì˜ ì •ë³´ë¡œ SQLAlchemy DB ì—”ì§„ ìƒì„±
        """
        load_dotenv()
        db_user = os.environ.get("DB_USER")
        db_pass = os.environ.get("DB_PASSWORD")
        db_host = os.environ.get("DB_HOST")
        db_port = os.environ.get("DB_PORT")
        db_name = os.environ.get("DB_NAME")

        if not all([db_user, db_pass, db_host, db_port, db_name]):
            print("ê²½ê³ : DB ì ‘ì† ì •ë³´(.env)ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. DB ë¡œë“œì— ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return None

        DATABASE_URL = f"postgresql+psycopg2://{db_user}:{db_pass}@{db_host}:{db_port}/{db_name}"

        try:
            engine = create_engine(DATABASE_URL)
            with engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            print("âœ… DB ì—°ê²° ì„±ê³µ")
            return engine
        except Exception as e:
            print(f"âŒ DB ì—”ì§„ ìƒì„± ë˜ëŠ” ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return None

    def load_nutrition_data(self):
        """
        (ë””ë²„ê¹… ëª¨ë“œ) ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ê³¼ì •ì˜ ì—ëŸ¬ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.
        """
        print("ğŸ”„ [1ë‹¨ê³„] DB ë°ì´í„° ë¡œë“œ ì‹œì‘...")

        if self.db_engine is None:
            print("âŒ ì˜¤ë¥˜: DB ì—”ì§„ ì—†ìŒ. ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©.")
            df = self._get_sample_data()
        else:
            # ìµœì¢… ì¿¼ë¦¬ (ì¹´í…Œê³ ë¦¬ JOIN ì œê±°ë¨)
            sql_query = """
            SELECT
                m.name AS "ì œí’ˆëª…",
                r.name AS "ì‹ë‹¹ëª…",
                m.price AS "ê°€ê²©",
                m.calories AS "ì—´ëŸ‰",
                m.tags AS "íƒœê·¸",          
                r.rating AS "í‰ì ",
                r.open_time AS "ì˜¤í”ˆì‹œê°„",
                r.close_time AS "ë§ˆê°ì‹œê°„",
                r.campus AS "ìº í¼ìŠ¤",
                '' AS "ì¹´í…Œê³ ë¦¬"
            FROM menus m
            JOIN restaurants r ON m.restaurants_id = r.restaurants_id
            """
            try:
                df = pd.read_sql(text(sql_query), self.db_engine)
                print(f"âœ… DB ë°ì´í„° ë¡œë“œ ì„±ê³µ! ({len(df)}ê°œ ë©”ë‰´ ê°€ì ¸ì˜´)")
            except Exception as e:
                print(f"âŒ DB ë¡œë“œ ì‹¤íŒ¨: {e}")
                df = self._get_sample_data()

        # --- ì „ì²˜ë¦¬ ë””ë²„ê¹… ì‹œì‘ ---
        print("ğŸ”„ [2ë‹¨ê³„] ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
        try:
            # 1. ì‹œê°„ ë³€í™˜
            # (ì´ë¯¸ time ê°ì²´ì¼ ìˆ˜ë„ ìˆê³  ë¬¸ìì—´ì¼ ìˆ˜ë„ ìˆì–´ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
            def safe_time_convert(x):
                if pd.isna(x): return None
                if isinstance(x, time): return x  # ì´ë¯¸ ì‹œê°„ ê°ì²´ë©´ ê·¸ëŒ€ë¡œ
                try:
                    return pd.to_datetime(str(x), format='%H:%M:%S').time()
                except:
                    return None

            df['ì˜¤í”ˆì‹œê°„'] = df['ì˜¤í”ˆì‹œê°„'].apply(safe_time_convert)
            df['ë§ˆê°ì‹œê°„'] = df['ë§ˆê°ì‹œê°„'].apply(safe_time_convert)
            print("   - ì‹œê°„ ë°ì´í„° ë³€í™˜ ì™„ë£Œ")

            # 2. í‰ì  ì²˜ë¦¬
            df['í‰ì '] = pd.to_numeric(df['í‰ì '], errors='coerce').fillna(3.0)
            print("   - í‰ì  ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")

            # 3. ìº í¼ìŠ¤ ì²˜ë¦¬ (ë¦¬ìŠ¤íŠ¸ -> ë¬¸ìì—´)
            def clean_campus(x):
                if isinstance(x, list):
                    return str(x[0]) if len(x) > 0 else 'ì •ë³´ì—†ìŒ'
                if pd.isna(x):
                    return 'ì •ë³´ì—†ìŒ'
                return str(x)

            df['ìº í¼ìŠ¤'] = df['ìº í¼ìŠ¤'].apply(clean_campus)
            print("   - ìº í¼ìŠ¤ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")

            # 4. ì—´ëŸ‰ ì²˜ë¦¬
            df['ì—´ëŸ‰'] = pd.to_numeric(df['ì—´ëŸ‰'], errors='coerce')
            df['ì—´ëŸ‰'] = df['ì—´ëŸ‰'].fillna(df['ì—´ëŸ‰'].median())
            print("   - ì—´ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")

            # 5. íƒœê·¸ ì²˜ë¦¬
            if 'íƒœê·¸' in df.columns:
                # DBì—ì„œ ë¬¸ìì—´('ë°¥,êµ­')ë¡œ ì˜¬ ìˆ˜ë„ ìˆê³  ë¦¬ìŠ¤íŠ¸(['ë°¥','êµ­'])ë¡œ ì˜¬ ìˆ˜ë„ ìˆìŒ
                df['íƒœê·¸'] = df['íƒœê·¸'].apply(
                    lambda x: x if isinstance(x, list) else (str(x).split(',') if pd.notna(x) and x else [])
                )
            else:
                df['íƒœê·¸'] = [[] for _ in range(len(df))]
            print("   - íƒœê·¸ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")

            # 6. ì¹´í…Œê³ ë¦¬ ì±„ìš°ê¸°
            if 'ì¹´í…Œê³ ë¦¬' in df.columns:
                df['ì¹´í…Œê³ ë¦¬'] = df['íƒœê·¸']
            print("   - ì¹´í…Œê³ ë¦¬ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")

            # 7. ìµœì¢… ì €ì¥
            self.menu_df = df
            print(f"âœ… [ì™„ë£Œ] ìµœì¢… ë©”ë‰´ ë°ì´í„° ì¤€ë¹„ë¨: {len(df)}ê°œ")
            return df

        except Exception as e:
            print(f"âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] ì „ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()  # ìì„¸í•œ ì—ëŸ¬ ìœ„ì¹˜ ì¶œë ¥
            return None

    def _get_sample_data(self):
        """
        DB ì—°ê²° ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•˜ëŠ” ìƒ˜í”Œ ë°ì´í„° (í‰ì , ì‹œê°„, ìº í¼ìŠ¤ ì¶”ê°€)
        """
        print("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...")
        return pd.DataFrame([
            {'ì œí’ˆëª…': 'ê¹€ì¹˜ì°Œê°œ', 'ì‹ë‹¹ëª…': 'í•œì‹ë‹¹ A', 'ê°€ê²©': 8000, 'ì—´ëŸ‰': 480, 'ì¹´í…Œê³ ë¦¬': 'í•œì‹,ì¸ë¬¸ê³„ìº í¼ìŠ¤', 'íƒœê·¸': 'ë°¥,êµ­ë¬¼,ë¼ì§€ê³ ê¸°', 'í‰ì ': 4.2,
             'ì˜¤í”ˆì‹œê°„': '10:00:00', 'ë§ˆê°ì‹œê°„': '22:00:00', 'ìº í¼ìŠ¤': 'ì¸ë¬¸ê³„ìº í¼ìŠ¤'},
            {'ì œí’ˆëª…': 'ë¹„ê±´ ë¹„ë¹”ë°¥', 'ì‹ë‹¹ëª…': 'í•œì‹ë‹¹ A', 'ê°€ê²©': 8000, 'ì—´ëŸ‰': 550, 'ì¹´í…Œê³ ë¦¬': 'í•œì‹,ì¸ë¬¸ê³„ìº í¼ìŠ¤,ì±„ì‹', 'íƒœê·¸': 'ë°¥,ì•¼ì±„,ë¹„ê±´', 'í‰ì ': 4.2,
             'ì˜¤í”ˆì‹œê°„': '10:00:00', 'ë§ˆê°ì‹œê°„': '22:00:00', 'ìº í¼ìŠ¤': 'ì¸ë¬¸ê³„ìº í¼ìŠ¤'},
            {'ì œí’ˆëª…': 'ì œìœ¡ë³¶ìŒ', 'ì‹ë‹¹ëª…': 'í•œì‹ë‹¹ B', 'ê°€ê²©': 8500, 'ì—´ëŸ‰': 620, 'ì¹´í…Œê³ ë¦¬': 'í•œì‹,ìì—°ê³„ìº í¼ìŠ¤', 'íƒœê·¸': 'ë°¥,ê³ ê¸°,ë¼ì§€ê³ ê¸°', 'í‰ì ': 4.0,
             'ì˜¤í”ˆì‹œê°„': '09:00:00', 'ë§ˆê°ì‹œê°„': '21:00:00', 'ìº í¼ìŠ¤': 'ìì—°ê³„ìº í¼ìŠ¤'},
            {'ì œí’ˆëª…': 'ì‹¬ì•¼ ë¼ë©˜', 'ì‹ë‹¹ëª…': 'ì¼ì‹ë‹¹ C', 'ê°€ê²©': 9000, 'ì—´ëŸ‰': 650, 'ì¹´í…Œê³ ë¦¬': 'ì¼ì‹,ìì—°ê³„ìº í¼ìŠ¤', 'íƒœê·¸': 'ë©´,êµ­ë¬¼', 'í‰ì ': 4.5,
             'ì˜¤í”ˆì‹œê°„': '18:00:00', 'ë§ˆê°ì‹œê°„': '02:00:00', 'ìº í¼ìŠ¤': 'ìì—°ê³„ìº í¼ìŠ¤'},  # ì•¼ê°„ ì˜ì—…
            {'ì œí’ˆëª…': 'ì¹˜í‚¨ ì¼€ë°¥', 'ì‹ë‹¹ëª…': 'ì¼€ë°¥ ì „ë¬¸ì ', 'ê°€ê²©': 7000, 'ì—´ëŸ‰': 310, 'ì¹´í…Œê³ ë¦¬': 'ê¸°íƒ€,ìì—°ê³„ìº í¼ìŠ¤,ë¬´ìŠ¬ë¦¼', 'íƒœê·¸': 'ë¹µ,ê°€ë²¼ìš´,í• ë„',
             'í‰ì ': 4.8, 'ì˜¤í”ˆì‹œê°„': '11:00:00', 'ë§ˆê°ì‹œê°„': '20:00:00', 'ìº í¼ìŠ¤': 'ìì—°ê³„ìº í¼ìŠ¤'},
            {'ì œí’ˆëª…': 'ì €ë‹¹ ë¹„ê±´ ìƒŒë“œìœ„ì¹˜', 'ì‹ë‹¹ëª…': 'ìƒŒë“œìœ„ì¹˜ ì „ë¬¸ì ', 'ê°€ê²©': 7500, 'ì—´ëŸ‰': 372, 'ì¹´í…Œê³ ë¦¬': 'ì–‘ì‹,ì¸ë¬¸ê³„ìº í¼ìŠ¤,ì±„ì‹,ì €ë‹¹', 'íƒœê·¸': 'ìƒŒë“œìœ„ì¹˜,ë¹„ê±´',
             'í‰ì ': 4.1, 'ì˜¤í”ˆì‹œê°„': '08:00:00', 'ë§ˆê°ì‹œê°„': '17:00:00', 'ìº í¼ìŠ¤': 'ì¸ë¬¸ê³„ìº í¼ìŠ¤'},  # ì•„ì¹¨ ê°€ëŠ¥
        ])

    def extract_features(self):
        """
        'í‰ì 'ì„ ìˆ˜ì¹˜í˜• í”¼ì²˜ì—, 'ìº í¼ìŠ¤'ë¥¼ ë”ë¯¸ í”¼ì²˜ì— ì¶”ê°€
        """
        if self.menu_df is None:
            print("ì˜¤ë¥˜: ë©”ë‰´ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        df = self.menu_df.copy()

        numeric_features = ['ì—´ëŸ‰', 'ê°€ê²©', 'í‰ì ']

        for col in numeric_features:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
                df[col] = df[col].fillna(df[col].median())
            else:
                print(f"ê²½ê³ : '{col}' ì»¬ëŸ¼ì´ ì—†ì–´ í”¼ì²˜ ì¶”ì¶œì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")

        numeric_features = [col for col in numeric_features if col in df.columns]

        if 'ì—´ëŸ‰' in df.columns:
            df['ì¹¼ë¡œë¦¬_ë ˆë²¨'] = pd.cut(df['ì—´ëŸ‰'], bins=[-np.inf, 400, 600, np.inf], labels=[0, 1, 2], right=True)

        if 'ê°€ê²©' in df.columns:
            df['ê°€ê²©_ë ˆë²¨'] = pd.cut(df['ê°€ê²©'], bins=[-np.inf, 7000, 9000, np.inf], labels=[0, 1, 2], right=True)

        # 'ìº í¼ìŠ¤' (ë‹¨ì¼ ê°’) ì›-í•« ì¸ì½”ë”©
        if 'ìº í¼ìŠ¤' in df.columns:
            campus_dummies = pd.get_dummies(df['ìº í¼ìŠ¤'], prefix='ìº í¼ìŠ¤')
            df = pd.concat([df, campus_dummies], axis=1)

        # 'ì¹´í…Œê³ ë¦¬' (ë‹¤ì¤‘ ê°’) ì›-í•« ì¸ì½”ë”©
        if 'ì¹´í…Œê³ ë¦¬' in df.columns:
            all_categories = set(cat for cats in df['ì¹´í…Œê³ ë¦¬'] for cat in cats if cat)
            for cat in all_categories:
                df[f'ì¹´í…Œê³ ë¦¬_{cat}'] = df['ì¹´í…Œê³ ë¦¬'].apply(lambda x: 1 if cat in x else 0)

        # 'íƒœê·¸' (ë‹¤ì¤‘ ê°’) ì›-í•« ì¸ì½”ë”©
        if 'íƒœê·¸' in df.columns:
            all_tags = set(tag for tags in df['íƒœê·¸'] for tag in tags if tag)
            for tag in all_tags:
                df[f'íƒœê·¸_{tag}'] = df['íƒœê·¸'].apply(lambda x: 1 if tag in x else 0)

        feature_cols = numeric_features
        feature_cols = [col for col in feature_cols if col in df.columns]

        if feature_cols:
            df[feature_cols] = self.scaler.fit_transform(df[feature_cols])
        else:
            print("ê²½ê³ : ì •ê·œí™”í•  ìˆ˜ì¹˜í˜• í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

        tag_cols = [col for col in df.columns if col.startswith('íƒœê·¸_')]
        category_cols = [col for col in df.columns if col.startswith('ì¹´í…Œê³ ë¦¬_') or col.startswith('ìº í¼ìŠ¤_')]
        level_cols = ['ì¹¼ë¡œë¦¬_ë ˆë²¨', 'ê°€ê²©_ë ˆë²¨']
        level_cols = [col for col in level_cols if col in df.columns]

        all_feature_cols = feature_cols + tag_cols + category_cols + level_cols
        all_feature_cols = [col for col in all_feature_cols if col in df.columns]

        self.menu_features = df[all_feature_cols].values
        print(f"âœ… í”¼ì²˜ ì¶”ì¶œ ì™„ë£Œ: {self.menu_features.shape[1] if isinstance(self.menu_features, np.ndarray) else 0}ê°œ í”¼ì²˜")
        return df

    def calculate_scores(self, user_preferences: UserPreferences):
        """
        (ìˆ˜ì •ë¨) 'ì €ë‹¹(LOW_SUGAR)' í•„í„° ì œê±°, 'VEGAN', 'MUSLIM' í•„í„° ë²„ê·¸ ìˆ˜ì •
        """
        if self.menu_df is None:
            raise ValueError("ë©”ë‰´ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        df = self.menu_df.copy()
        scores = np.ones(len(df))  # 1ì ìœ¼ë¡œ ì‹œì‘

        # --- [1. ê°•ë ¥í•œ í•„í„° ë¡œì§ (Hard Filters)] ---

        # (A) [ìˆ˜ì •ë¨] VEGAN/MUSLIM í•„í„° (DB 'ì¹´í…Œê³ ë¦¬' ì»¬ëŸ¼ ê²€ì‚¬)
        if user_preferences.category and 'ì¹´í…Œê³ ë¦¬' in df.columns:
            category_upper = user_preferences.category.upper()

            if category_upper == "VEGAN":  # <-- UserInputì˜ 'vegan'
                is_not_vegan = df['ì¹´í…Œê³ ë¦¬'].apply(
                    lambda cats: 'ì±„ì‹' not in cats and 'ë¹„ê±´' not in cats  # DBì˜ 'ì±„ì‹'
                )
                scores[is_not_vegan] = 0.0

            if category_upper == "MUSLIM":  # <-- UserInputì˜ 'muslim'
                is_not_muslim = df['ì¹´í…Œê³ ë¦¬'].apply(
                    lambda cats: 'ë¬´ìŠ¬ë¦¼' not in cats and 'í• ë„' not in cats  # DBì˜ 'ë¬´ìŠ¬ë¦¼'
                )
                scores[is_not_muslim] = 0.0

                if 'íƒœê·¸' in df.columns:
                    has_pork = df['íƒœê·¸'].apply(lambda tags: 'ë¼ì§€ê³ ê¸°' in tags)
                    scores[has_pork] = 0.0

                    # [ì œê±°ë¨] LOW_SUGAR (ì €ë‹¹) í•„í„°
            # if category_upper == "LOW_SUGAR":
            #    ...

        # (B) Location(Campus) í•„í„° (DB 'ìº í¼ìŠ¤' ì»¬ëŸ¼ ê²€ì‚¬)
        if user_preferences.location and 'ìº í¼ìŠ¤' in df.columns:
            location_map = {
                'science_campus': 'ìì—°ê³„ìº í¼ìŠ¤',
                'humanities_campus': 'ì¸ë¬¸ê³„ìº í¼ìŠ¤'
            }
            target_campuses = [location_map.get(loc) for loc in user_preferences.location if location_map.get(loc)]

            if target_campuses:
                # [ìˆ˜ì •] "ë‘˜ë‹¤" ì¼€ì´ìŠ¤ ê³ ë ¤ (v2.9 ì œì•ˆ ë°©ì‹)
                is_match = df['ìº í¼ìŠ¤'].apply(
                    lambda menu_campus: (menu_campus in target_campuses) or (menu_campus == 'ë‘˜ë‹¤')
                )
                scores[~is_match] = 0.0  # ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì œì™¸

                # (ì°¸ê³ : ë§Œì•½ v2.8ì˜ N:M ë¦¬ìŠ¤íŠ¸ ë°©ì‹('ì´ìº ,ë¬¸ìº ')ì„ ì“°ë ¤ë©´ ì•„ë˜ ì½”ë“œë¡œ ëŒ€ì²´)
                # has_matching_campus = df['ìº í¼ìŠ¤'].apply(
                #    lambda menu_campuses: any(target in menu_campuses for target in target_campuses)
                # )
                # scores[~has_matching_campus] = 0.0

        # (C) Operating Time í•„í„° (DB 'ì˜¤í”ˆ/ë§ˆê°ì‹œê°„' ê²€ì‚¬)
        meal_time_map = {
            'ì•„ì¹¨': time(9, 0),  # 9:00 AM
            'ì ì‹¬': time(13, 0),  # 1:00 PM
            'ì €ë…': time(19, 0)  # 7:00 PM
        }
        target_time = meal_time_map.get(user_preferences.meal_type)

        if target_time and 'ì˜¤í”ˆì‹œê°„' in df.columns and 'ë§ˆê°ì‹œê°„' in df.columns:

            def is_open(row):
                open_t = row['ì˜¤í”ˆì‹œê°„']
                close_t = row['ë§ˆê°ì‹œê°„']
                if pd.isna(open_t) or pd.isna(close_t):
                    return True
                if open_t <= close_t:
                    return open_t <= target_time <= close_t
                else:
                    return target_time >= open_t or target_time <= close_t

            is_not_open = ~df.apply(is_open, axis=1)
            scores[is_not_open] = 0.0

        # --- [2. ê°€ì‚°ì  ë¡œì§ (Soft Filters)] ---

        # (A) ì˜ˆì‚° ì í•©ë„ (í•˜ë“œ í•„í„° + ê°€ì‚°ì )
        if (user_preferences.budget is not None) and (user_preferences.budget > 0) and ('ê°€ê²©' in df.columns):
            within = df['ê°€ê²©'] <= user_preferences.budget
            scores[~within.values] = 0.0

            if user_preferences.min_budget:
                within_min = df['ê°€ê²©'] >= user_preferences.min_budget
                scores[~within_min.values] = 0.0

            if scores.sum() > 0:
                price_diff = (df['ê°€ê²©'] - user_preferences.budget).abs()
                price_score = 1 - (price_diff / max(user_preferences.budget, 1)).clip(0, 1)
                scores[scores > 0] += price_score[scores > 0] * 3.0

        # (B) Rating(í‰ì ) ê°€ì‚°ì 
        if 'í‰ì ' in df.columns:
            rating_score = (df['í‰ì '] / 5.0)
            scores[scores > 0] += rating_score[scores > 0] * 1.5

            # (C) ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (íƒœê·¸)
        if user_preferences.user_prompt and 'íƒœê·¸' in df.columns:
            prompt_lower = user_preferences.user_prompt.lower()
            negative_keywords = []
            positive_keywords = []

            if 'ë§ê³ ' in prompt_lower or 'ë¹¼ê³ ' in prompt_lower or 'ì œì™¸' in prompt_lower:
                words = prompt_lower.replace(',', ' ').split()
                for i, word in enumerate(words):
                    if word in ['ë§ê³ ', 'ë¹¼ê³ ', 'ì œì™¸']:
                        if i > 0:
                            negative_keywords.append(words[i - 1])

            if 'ë°¥' in prompt_lower: positive_keywords.append('ë°¥')
            if 'ê³ ê¸°' in prompt_lower: positive_keywords.append('ê³ ê¸°')
            if 'ê°€ë²¼ìš´' in prompt_lower: positive_keywords.append('ê°€ë²¼ìš´')
            if 'ë“ ë“ í•œ' in prompt_lower: positive_keywords.append('ë“ ë“ í•œ')

            for neg_keyword in negative_keywords:
                has_negative = df['íƒœê·¸'].apply(
                    lambda tags: any(neg_keyword in tag for tag in tags) if isinstance(tags, list) else False
                )
                scores[has_negative] = 0.0

            for pos_keyword in positive_keywords:
                has_positive = df['íƒœê·¸'].apply(
                    lambda tags: any(pos_keyword in tag for tag in tags) if isinstance(tags, list) else False
                )
                scores[scores > 0] += has_positive.astype(float)[scores > 0] * 2.0

        # (D) ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (ì˜ˆ: 'í•œì‹', 'ì¼ì‹') - UserInputì— ì´ í•„ë“œê°€ ì—†ìœ¼ë¯€ë¡œ í˜„ì¬ ë¹„í™œì„±
        if user_preferences.preferred_categories and 'ì¹´í…Œê³ ë¦¬' in df.columns:
            for category in user_preferences.preferred_categories:
                has_category = df['ì¹´í…Œê³ ë¦¬'].apply(
                    lambda cats: category in cats if isinstance(cats, list) else False
                )
                scores[scores > 0] += has_category.astype(float)[scores > 0] * 2.0

        # (E) ì˜ì–‘ ì„ í˜¸ë„ (DIET)
        if user_preferences.prefer_low_calorie and 'ì—´ëŸ‰' in df.columns:
            if df['ì—´ëŸ‰'].max() > df['ì—´ëŸ‰'].min():
                calorie_score = 1 - ((df['ì—´ëŸ‰'] - df['ì—´ëŸ‰'].min()) / (df['ì—´ëŸ‰'].max() - df['ì—´ëŸ‰'].min()))
                scores[scores > 0] += calorie_score[scores > 0] * 1.5

        # (F) ì‹ì‚¬ ì‹œê°„ëŒ€ (íƒœê·¸)
        if 'íƒœê·¸' in df.columns:
            meal_tags = {
                'ì•„ì¹¨': ['ê°€ë²¼ìš´', 'ìƒŒë“œìœ„ì¹˜', 'ìƒëŸ¬ë“œ'],
                'ì ì‹¬': ['ë“ ë“ í•œ', 'ê³ ë‹¨ë°±', 'ì˜ì–‘ê· í˜•', 'ë°¥', 'ê³ ê¸°'],
                'ì €ë…': ['ë“ ë“ í•œ', 'êµ­ë¬¼', 'ë”°ëœ»í•œ', 'ë°¥']
            }
            if user_preferences.meal_type in meal_tags:
                for tag in meal_tags[user_preferences.meal_type]:
                    tag_match = df['íƒœê·¸'].apply(lambda tags: tag in tags if isinstance(tags, list) else False)
                    scores[scores > 0] += tag_match.astype(float)[scores > 0] * 1.0

        # ì •ê·œí™” (ìœ ì§€)
        if scores.max() > 0:
            scores = scores / scores.max()

        return scores


# --- 4. LangChain ë° LLM ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼) ---

load_dotenv()
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
parser = PydanticOutputParser(pydantic_object=FinalRecommendation)
if not OPENAI_API_KEY:
    print("ê²½ê³ : OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    llm = None
else:
    try:
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.6, api_key=OPENAI_API_KEY)
    except ImportError:
        print("langchain_openaiê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        llm = None
    except Exception as e:
        print(f"OpenAI LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. (API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”)")
        llm = None
prompt_template = """
ë‹¹ì‹ ì€ ê³ ë ¤ëŒ€í•™êµ ê·¼ì²˜ ë§›ì§‘ ë©”ë‰´ ì¶”ì²œ AI 'MenuMate'ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì„¸ë¶€ ìš”ì²­ê³¼ AI Aê°€ 1ì°¨ í•„í„°ë§í•œ ë©”ë‰´ í›„ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.

[í›„ë³´ ë¦¬ìŠ¤íŠ¸] (ì´ë¦„, ê°€ê²©, AI A ì ìˆ˜, íƒœê·¸ ìˆœ)
{candidates_str}

[ì‚¬ìš©ì ì„¸ë¶€ ìš”ì²­]
"{user_prompt}"

[ì‚¬ìš©ì ê°€ê²© ì œí•œ]
{price_str}

[ì‚¬ìš©ìê°€ ì¶”ì²œë°›ê¸¸ ì›í•˜ëŠ” ë¼ë‹ˆ]
{target_meals_str}

[ì§€ì‹œ]
1. [í›„ë³´ ë¦¬ìŠ¤íŠ¸] ì¤‘ì—ì„œ [ì‚¬ìš©ì ì„¸ë¶€ ìš”ì²­]ê³¼ [ì‚¬ìš©ì ê°€ê²© ì œí•œ]ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ë©”ë‰´ë¥¼ ê³ ë¥´ì„¸ìš”.
2. [ì‚¬ìš©ìê°€ ì¶”ì²œë°›ê¸¸ ì›í•˜ëŠ” ë¼ë‹ˆ] ëª©ë¡({target_meals_str})ì— ìˆëŠ” ìŠ¬ë¡¯ì—ë§Œ ì¶”ì²œ ë©”ë‰´ë¥¼ ì±„ì›Œì£¼ì„¸ìš”.
3. ê° í›„ë³´ì˜ 'price' ì •ë³´ë¥¼ [ì¶œë ¥ JSON]ì˜ 'price' í•„ë“œì— ì •í™•íˆ ê¸°ì…í•´ì£¼ì„¸ìš”.
4. ì‚¬ìš©ì ìš”ì²­ "{user_prompt}"ì„ ë°˜ë“œì‹œ ê³ ë ¤í•˜ì„¸ìš”. (ì˜ˆ: "êµ­ìˆ˜ ë§ê³  ë°¥" â†’ ë©´ ì¢…ë¥˜ ë©”ë‰´ëŠ” ì œì™¸)
5. ì¶”ì²œ ë©”ë‰´ë¥¼ ì„ ì •í•œ í›„, [ì‚¬ìš©ì ì„¸ë¶€ ìš”ì²­]ì„ ë°”íƒ•ìœ¼ë¡œ ê·¸ ì´ìœ ë¥¼ ìš”ì•½í•˜ëŠ” 1~3ê°œì˜ 'reason_hashtags'ë¥¼ ë°˜ë“œì‹œ ìƒì„±í•´ì£¼ì„¸ìš”. (ì˜ˆ: '#ì†í¸í•œ', '#ë“ ë“ í•œ', '#ê°€ì„±ë¹„')
6. ëª©ë¡ì— ì—†ëŠ” ë‹¤ë¥¸ ë¼ë‹ˆ ìŠ¬ë¡¯ì€ ë°˜ë“œì‹œ nullë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
7. ë§Œì•½ ì‚¬ìš©ìê°€ 'ì ì‹¬'ë§Œ ì›í–ˆë‹¤ë©´ 'morning'ê³¼ 'dinner'ëŠ” ë°˜ë“œì‹œ nullì´ì–´ì•¼ í•©ë‹ˆë‹¤.

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤ (ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”):
{format_instructions}
"""
prompt = ChatPromptTemplate.from_template(
    template=prompt_template,
    partial_variables={"format_instructions": parser.get_format_instructions()}
)
if llm:
    chain = prompt | llm | parser
else:
    chain = None
    print("LLM ì²´ì¸ êµ¬ì„± ì‹¤íŒ¨. /recommend ì—”ë“œí¬ì¸íŠ¸ê°€ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# --- 5. FastAPI ì•± ë° ìºì‹± ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼) ---

app = FastAPI(
    title="MenuMate AI - í†µí•© ì¶”ì²œ ëª¨ë“ˆ",
    description="ì˜ì–‘ì„±ë¶„ ê¸°ë°˜ í›„ë³´ ìƒì„±(A) ë° LLM ìµœì¢… ì¶”ì²œ(B) í†µí•© API"
)
preprocessor: Optional[MenuDataPreprocessor] = None
cache: Optional[redis.Redis] = None


@app.on_event("startup")
async def startup():
    """ì„œë²„ ì‹œì‘ ì‹œ ë°ì´í„° ë¡œë“œ, ì „ì²˜ë¦¬, ìºì‹œ ì—°ê²°"""
    global preprocessor, cache
    preprocessor = MenuDataPreprocessor()
    preprocessor.load_nutrition_data()
    preprocessor.extract_features()
    print("âœ… (AI A) ë°ì´í„° ì „ì²˜ë¦¬ ëª¨ë“ˆ ì¤€ë¹„ ì™„ë£Œ!")
    try:
        cache = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
        cache.ping()
        print("âœ… (AI B) Redis ìºì‹œ ì„œë²„ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except redis.ConnectionError as e:
        print(f"ê²½ê³ : Redis ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìºì‹±ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. (ì˜¤ë¥˜: {e})")
        cache = None
    print("âœ… í†µí•© AI ëª¨ë“ˆ ì¤€ë¹„ ì™„ë£Œ!")


@app.get("/")
async def root():
    return {
        "service": "MenuMate AI (Combined A+B)",
        "status": "running",
        "version": "2.6.1 (No LowSugar, Rating, Time, Campus)",
        "llm_ready": (chain is not None),
        "preprocessor_ready": (preprocessor is not None and preprocessor.menu_df is not None),
        "db_connected": (preprocessor is not None and preprocessor.db_engine is not None)
    }


# --- 6. ë‚´ë¶€ ë¡œì§ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---

async def _generate_candidates(preferences: UserPreferences) -> RecommendationRequest:
    if preprocessor is None or preprocessor.menu_df is None:
        raise HTTPException(status_code=503, detail="ë°ì´í„° ì „ì²˜ë¦¬ê¸°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    try:
        scores = preprocessor.calculate_scores(preferences)
        df = preprocessor.menu_df.copy()
        df['base_score'] = scores
        df_filtered = df[df['base_score'] > 0]
        df_sorted = df_filtered.sort_values('base_score', ascending=False).head(20)
        candidates = []
        for _, row in df_sorted.iterrows():  # df -> df_sorted
            candidates.append(MenuCandidate(
                restaurant_name=row['ì‹ë‹¹ëª…'],
                menu_name=row['ì œí’ˆëª…'],
                price=int(row['ê°€ê²©']),
                base_score=float(row['base_score']),
                tags=row['íƒœê·¸'] if isinstance(row['íƒœê·¸'], list) else []
            ))
        ai_b_request = RecommendationRequest(
            candidates=candidates,
            user_prompt=preferences.user_prompt or "ë§›ìˆê³  ê±´ê°•í•œ ë©”ë‰´",
            price=PriceRange(
                min=preferences.min_budget,
                max=preferences.budget
            ) if (preferences.budget or preferences.min_budget) else None,
            target_meals=preferences.target_meals,
            conversation_history=[]
        )
        return ai_b_request
    except Exception as e:
        print(f"í›„ë³´êµ° ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í›„ë³´êµ° ìƒì„±(AI A) ì‹¤íŒ¨: {str(e)}")


async def _refine_recommendations(request: RecommendationRequest) -> FinalRecommendation:
    if chain is None:
        raise HTTPException(status_code=503, detail="LLM ì²´ì¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (.env íŒŒì¼ ë˜ëŠ” API í‚¤ í™•ì¸ í•„ìš”)")
    cache_key = None
    if cache:
        try:
            cache_key = f"recommend:{hash(request.model_dump_json())}"
            cached_result = cache.get(cache_key)
            if cached_result:
                print("ìºì‹œëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return FinalRecommendation.model_validate_json(cached_result)
        except Exception as e:
            print(f"ìºì‹œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    candidates_str = "\n".join(
        [f"- {c.restaurant_name} '{c.menu_name}' (ê°€ê²©: {c.price}ì›, ì ìˆ˜: {c.base_score:.2f}, íƒœê·¸: {c.tags})"
         for c in request.candidates]
    )
    price_str = "ì œí•œ ì—†ìŒ"
    if request.price:
        parts = []
        if request.price.min is not None:
            parts.append(f"{request.price.min}ì› ì´ìƒ")
        if request.price.max is not None:
            parts.append(f"{request.price.max}ì› ì´í•˜")
        if parts:
            price_str = " ".join(parts)
    target_meals_str = ", ".join(request.target_meals)
    try:
        print(f"LLM í˜¸ì¶œ ì‹œì‘: (User: {request.user_prompt}, Price: {price_str}, Meals: {target_meals_str})")
        result = await chain.ainvoke({
            "candidates_str": candidates_str,
            "user_prompt": request.user_prompt,
            "price_str": price_str,
            "target_meals_str": target_meals_str,
            "history": "\n".join(request.conversation_history or [])
        })
        if cache and cache_key:
            try:
                cache.set(cache_key, result.model_dump_json(), ex=3600)
                print("ìƒˆ ê²°ê³¼ë¥¼ ìƒì„±í•˜ê³  ìºì‹œì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"ìºì‹œ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return result
    except Exception as e:
        print(f"LLM íŒŒì‹± ë˜ëŠ” API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë©”ë‰´ ì¶”ì²œ(AI B) ì‹¤íŒ¨: {str(e)}")


# --- 7. í†µí•© ì—”ë“œí¬ì¸íŠ¸ (ìƒˆ JSON í˜•ì‹ ì‚¬ìš©) ---

@app.post("/recommend", response_model=FinalRecommendation)
async def get_recommendation(user_input: UserInput):
    try:
        print(
            f"ì…ë ¥ ë°›ìŒ: category={user_input.category}, meals={user_input.meals}, prompt='{user_input.prompt}', location={user_input.location}")
        preferences = convert_user_input(user_input)
        print(
            f"ë³€í™˜ ì™„ë£Œ: meal_type={preferences.meal_type}, category={preferences.category}, location={preferences.location}")
        print(f"1ë‹¨ê³„: í›„ë³´êµ° ìƒì„± ì‹œì‘")
        candidate_request = await _generate_candidates(preferences)
        if not candidate_request.candidates:
            print("1ë‹¨ê³„ ê²°ê³¼: ì¶”ì²œí•  í›„ë³´êµ°ì´ ì—†ìŠµë‹ˆë‹¤. (í•„í„° ì¡°ê±´ì´ ë„ˆë¬´ ë§ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
            return FinalRecommendation(morning=None, lunch=None, dinner=None)
        print(f"1ë‹¨ê³„ ì™„ë£Œ: {len(candidate_request.candidates)}ê°œ í›„ë³´ ìƒì„±")
        print("2ë‹¨ê³„: LLM ì •ì œ ì‹œì‘")
        final_recommendation = await _refine_recommendations(candidate_request)
        print("2ë‹¨ê³„ ì™„ë£Œ: ìµœì¢… ì¶”ì²œ ìƒì„±")
        return final_recommendation
    except HTTPException as he:
        raise he
    except Exception as e:
        print(f"ì „ì²´ ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì „ì²´ ì¶”ì²œ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {str(e)}")


# --- 8. ê¸°ì¡´ í˜¸í™˜ì„± ì—”ë“œí¬ì¸íŠ¸ (ì„ íƒì ) ---

@app.post("/recommend/full", response_model=FinalRecommendation)
async def get_full_recommendation(preferences: UserPreferences):
    try:
        print(
            f"1ë‹¨ê³„: í›„ë³´êµ° ìƒì„± ì‹œì‘ (User: {preferences.user_prompt}, Category: {preferences.category}, Location: {preferences.location})")
        candidate_request = await _generate_candidates(preferences)
        if not candidate_request.candidates:
            print("1ë‹¨ê³„ ê²°ê³¼: ì¶”ì²œí•  í›„ë³´êµ°ì´ ì—†ìŠµë‹ˆë‹¤.")
            return FinalRecommendation(morning=None, lunch=None, dinner=None)
        print(f"1ë‹¨ê³„ ì™„ë£Œ: {len(candidate_request.candidates)}ê°œ í›„ë³´ ìƒì„±")
        print("2ë‹¨ê³„: LLM ì •ì œ ì‹œì‘")
        final_recommendation = await _refine_recommendations(candidate_request)
        print("2ë‹¨ê³„ ì™„ë£Œ: ìµœì¢… ì¶”ì²œ ìƒì„±")
        return final_recommendation
    except HTTPException as he:
        raise he
    except Exception as e:
        print(f"ì „ì²´ ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì „ì²´ ì¶”ì²œ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {str(e)}")


# --- 9. í—¬í¼ ì—”ë“œí¬ì¸íŠ¸ ---

@app.get("/menu/all")
async def get_all_menus():
    """(ìˆ˜ì •ë¨) ì „ì²˜ë¦¬ëœ ë©”ë‰´ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ (ë””ë²„ê¹…ìš©)"""
    if preprocessor is None or preprocessor.menu_df is None:
        raise HTTPException(status_code=503, detail="ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")

    df = preprocessor.menu_df.copy()
    df['íƒœê·¸'] = df['íƒœê·¸'].apply(lambda x: ','.join(x) if isinstance(x, list) else '')
    df['ì¹´í…Œê³ ë¦¬'] = df['ì¹´í…Œê³ ë¦¬'].apply(lambda x: ','.join(x) if isinstance(x, list) else '')
    df['ì˜¤í”ˆì‹œê°„'] = df['ì˜¤í”ˆì‹œê°„'].apply(lambda x: x.strftime('%H:%M:%S') if isinstance(x, time) else None)
    df['ë§ˆê°ì‹œê°„'] = df['ë§ˆê°ì‹œê°„'].apply(lambda x: x.strftime('%H:%M:%S') if isinstance(x, time) else None)
    return df.to_dict(orient='records')


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "healthy",
        "preprocessor": preprocessor is not None,
        "llm": chain is not None,
        "cache": cache is not None,
        "db_connected": (preprocessor is not None and preprocessor.db_engine is not None)
    }


# --- 10. ì„œë²„ ì‹¤í–‰ ---

if __name__ == "__main__":
    print('ì„œë²„ì‹¤í–‰')
    uvicorn.run(app, host="0.0.0.0", port=8000)